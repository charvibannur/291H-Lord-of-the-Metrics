# Lord of the Metrics - Course Project for Advanced Data-Driven Text Mining (291-H)

## Project Overview:
Evaluating multilingual LLMs with word-based metrics is inconsistent due to linguistic diversity as morphologically rich non-English languages require finer granularity and modern LLMs using subword representations are misaligned with word-level evaluation. This work proposes a token-based global evaluation metric that aggressively penalizes errors while accounting for granularity offering a fair and standardized approach for multilingual LLM evaluation. We evaluate the performance of various models across different languages, comparing BLEU and hallucination scores. Our model consistently outperforms BLEU in most cases, with significant improvements in languages such as English, Hindi, German, and French.

## Proposed Methodology:

![image](https://github.com/user-attachments/assets/7ed8ca75-7fb9-42d8-8a8b-85dd490c28d8)

## Results
These are the observed results of our project.

<img width="475" alt="image" src="https://github.com/user-attachments/assets/3dddbd76-64e1-4248-b32b-33cb09080bc3">

## Collaborators:
1. Charvi Bannur
2. Shivani Chinta
3. Jayanth Tummalapenta

